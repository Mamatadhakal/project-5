{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730ea851-30e4-4566-82b7-e7fd50e43d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mamat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mamat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mamat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries for data manipulation and analysis\n",
    "import pandas as pd # For dataframes and data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import seaborn as sns # For enhanced data visualization\n",
    "\n",
    "# Importing Natural Language Toolkit (NLTK) components for text processing\n",
    "from nltk.corpus import stopwords # For common stopwords\n",
    "from nltk.tokenize import word_tokenize # For splitting text into words (tokens)\n",
    "from nltk.stem import WordNetLemmatizer # For reducing words to their base/dictionary form\n",
    "from nltk.stem import PorterStemmer # For reducing words to their root form (more aggressive than lemmatization)\n",
    "import string # For string operations and punctuation characters\n",
    "\n",
    "# Importing scikit-learn components for machine learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # For converting text to TF-IDF features\n",
    "from sklearn.model_selection import train_test_split # For splitting data into train/test sets\n",
    "from sklearn.linear_model import LogisticRegression  # For logistic regression classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score # For model evaluation\n",
    "\n",
    "# Importing NLTK and downloading necessary datasets/models\n",
    "import nltk\n",
    "nltk.download('punkt') # Downloading the Punkt tokenizer models\n",
    "nltk.download('stopwords') # Downloading common stopwords list\n",
    "nltk.download('wordnet') #download the WordNet lexical database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19894a2-c91a-47fb-a656-b1a0860869ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (568454, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the specified file path into a pandas DataFrame\n",
    "# The file is a zipped CSV containing product reviews from kraggle\n",
    "\n",
    "df = pd.read_csv('C:/Users/mamat/Downloads/Reviews.csv.zip')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\") # Print the shape (dimensions) of the DataFrame\n",
    "\n",
    "df.head() # Display the first 5 rows of the DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def5108c-d6e4-4854-9275-efc2f1fdff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568428 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info()) #to look at the data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0afd9c6-c66f-4ff4-a4fb-8cfcf2ba0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                         0\n",
      "ProductId                  0\n",
      "UserId                     0\n",
      "ProfileName               26\n",
      "HelpfulnessNumerator       0\n",
      "HelpfulnessDenominator     0\n",
      "Score                      0\n",
      "Time                       0\n",
      "Summary                   27\n",
      "Text                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum()) #to find out the null value in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36832096-fb7b-4bda-9d3e-50026b6f19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the 'Text' (review content) and 'Score' (rating) columns from the DataFrame\n",
    "# We keep only these two columns because:\n",
    "# - 'Text' contains the actual review text we'll analyze (our feature/X variable)\n",
    "# - 'Score' contains the numerical rating (typically 1-5 stars) which will be our target/y variable\n",
    "# This is a common setup for sentiment analysis tasks where we predict rating from text\n",
    "df = df[['Text', 'Score']]\n",
    "\n",
    "# Remove any rows that have missing values (NaN) in either column\n",
    "# This is important because:\n",
    "# - We can't analyze text that doesn't exist (missing Text)\n",
    "# - We can't train a model without known ratings (missing Score)\n",
    "# - Most ML algorithms cannot handle missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d2d381-b998-454d-a98b-29e39056d4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score\n",
       "0       I have bought several of the Vitality canned d...      5\n",
       "1       Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2       This is a confection that has been around a fe...      4\n",
       "3       If you are looking for the secret ingredient i...      2\n",
       "4       Great taffy at a great price.  There was a wid...      5\n",
       "...                                                   ...    ...\n",
       "568449  Great for sesame chicken..this is a good if no...      5\n",
       "568450  I'm disappointed with the flavor. The chocolat...      2\n",
       "568451  These stars are small, so you can give 10-15 o...      5\n",
       "568452  These are the BEST treats for training and rew...      5\n",
       "568453  I am very satisfied ,product is as advertised,...      5\n",
       "\n",
       "[568454 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #to look at the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a7a1d0-c05a-485f-8472-200c0487e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows: 174779\n"
     ]
    }
   ],
   "source": [
    "# Count total duplicate rows (all columns identical)\n",
    "print(\"Total duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b38b51-ceb3-4b10-917a-495ab8f145a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate reviews: 174875\n"
     ]
    }
   ],
   "source": [
    "# Count duplicates in just the 'Text' column\n",
    "print(\"Duplicate reviews:\", df['Text'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01581208-40ed-44e8-bcd9-10694fcc34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all completely duplicate rows (where ALL column values are identical)\n",
    "# This checks for rows where both Text AND Score are duplicates\n",
    "# keep='first' parameter keeps the first occurrence and drops subsequent duplicates\n",
    "# Note: The comment indicates there are none in this case, but we check anyway\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4adfa5-baac-4bb0-a42c-5f4191a0b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More specifically remove duplicate reviews based only on the 'Text' column\n",
    "# This ensures we don't have the exact same review text appearing multiple times\n",
    "# (even if they happen to have different scores, which would be unusual)\n",
    "# This is important because:\n",
    "# 1. Identical text should be treated as the same data point\n",
    "# 2. Prevents the model from overfitting to repeated text\n",
    "# 3. Reduces bias in cases where the same user might submit duplicate reviews\n",
    "df = df.drop_duplicates(subset=['Text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fa24ab-3a51-4871-b2ea-848c47817924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate reviews: 0\n"
     ]
    }
   ],
   "source": [
    "#rechecking if the duplicate is removed or not\n",
    "print(\"Duplicate reviews:\", df['Text'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac59eb01-ad53-4de6-9743-6af578514946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all entries in the 'Text' column to string type\n",
    "# This ensures consistent text processing by:\n",
    "# 1. Handling any non-string values that might exist in the data\n",
    "# 2. Guaranteeing all text processing functions will work properly since they expect string input\n",
    "# 3. Preventing potential errors during text vectorization or NLP operations\n",
    "df['Text'] = df['Text'].astype(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
